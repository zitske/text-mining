{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f0c04b8",
   "metadata": {},
   "source": [
    "# Carregamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7466f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewId</th>\n",
       "      <th>app_name</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3011</td>\n",
       "      <td>3011</td>\n",
       "      <td>3011</td>\n",
       "      <td>3011</td>\n",
       "      <td>3011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3011</td>\n",
       "      <td>10</td>\n",
       "      <td>3011</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>01e23c15-44bf-46b7-b280-40e880d9d49b</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>O app da Shopee é razoável. Apesar de ser fáci...</td>\n",
       "      <td>negative</td>\n",
       "      <td>disgust</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>303</td>\n",
       "      <td>1</td>\n",
       "      <td>1742</td>\n",
       "      <td>952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    reviewId app_name  \\\n",
       "count                                   3011     3011   \n",
       "unique                                  3011       10   \n",
       "top     01e23c15-44bf-46b7-b280-40e880d9d49b   Shopee   \n",
       "freq                                       1      303   \n",
       "\n",
       "                                                  content sentiment_polarity  \\\n",
       "count                                                3011               3011   \n",
       "unique                                               3011                  3   \n",
       "top     O app da Shopee é razoável. Apesar de ser fáci...           negative   \n",
       "freq                                                    1               1742   \n",
       "\n",
       "       sentiment Unnamed: 5  \n",
       "count       3011          1  \n",
       "unique         7          1  \n",
       "top      disgust          X  \n",
       "freq         952          1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('apps_reviews_validacao.xlsx - apps_reviews.csv', sep=',')\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c02a6a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O app da Shopee é razoável. Apesar de ser fácil de utilizar, apresenta alguns bugs. Por exemplo: Sugestão de palavra errada no campo de pesquisa que acarreta na busca errada. Sugestões de produtos que não têm nada a ver com coisas de nosso interesse. Dificuldade de acesso de alguns jogos ou travamento durante alguma jogada. Falhas para carregar certos anexos para avaliação dos produtos. No geral, são problemas que se pode contornar, pois não ocorrem com tanta frequência.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[0,'content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d5de07",
   "metadata": {},
   "source": [
    "# Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95145930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O app da Shopee é razoável  Apesar de ser fácil de utilizar  apresenta alguns bugs  Por exemplo  Sugestão de palavra errada no campo de pesquisa que acarreta na busca errada  Sugestões de produtos que não têm nada a ver com coisas de nosso interesse  Dificuldade de acesso de alguns jogos ou travamento durante alguma jogada  Falhas para carregar certos anexos para avaliação dos produtos  No geral  são problemas que se pode contornar  pois não ocorrem com tanta frequência '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import regex # trabalhar com expressões regulares\n",
    "data['content'] = data['content'].apply(lambda x: regex.sub(r'[^\\p{Latin}]', u' ', str(x)))\n",
    "data.loc[0,'content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a774366",
   "metadata": {},
   "source": [
    "# Colocando textos minusculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7338b00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o app da shopee é razoável  apesar de ser fácil de utilizar  apresenta alguns bugs  por exemplo  sugestão de palavra errada no campo de pesquisa que acarreta na busca errada  sugestões de produtos que não têm nada a ver com coisas de nosso interesse  dificuldade de acesso de alguns jogos ou travamento durante alguma jogada  falhas para carregar certos anexos para avaliação dos produtos  no geral  são problemas que se pode contornar  pois não ocorrem com tanta frequência '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['content'] = data['content'].apply(lambda x: str(x).lower())\n",
    "data.loc[0,'content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303dacbe",
   "metadata": {},
   "source": [
    "# Removendo stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b26c8d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\arthu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\arthu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Baixar os recursos necessários\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def remove_stopwords(texto):\n",
    "    # Obter a lista de stopwords em português\n",
    "    stops_list = stopwords.words(\"portuguese\")\n",
    "    # Tokenizar o texto\n",
    "    word_tokens = word_tokenize(texto)\n",
    "    # Remover as stopwords\n",
    "    texto_sem_stops = [w for w in word_tokens if w.lower() not in stops_list]\n",
    "    return \" \".join(texto_sem_stops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e388c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'app shopee razoável apesar fácil utilizar apresenta alguns bugs exemplo sugestão palavra errada campo pesquisa acarreta busca errada sugestões produtos têm nada ver coisas interesse dificuldade acesso alguns jogos travamento durante alguma jogada falhas carregar certos anexos avaliação produtos geral problemas pode contornar pois ocorrem tanta frequência'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['content'] = data['content'].apply(remove_stopwords)\n",
    "data.loc[0,'content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d071d780-b54c-4540-b01d-636e39d3dc8d",
   "metadata": {},
   "source": [
    "# Carregamento dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03e938c3-7f90-4902-a8d9-d71dabe86d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Preenchendo valores nulos na coluna 'content'\n",
    "data['content'] = data['content'].fillna('')\n",
    "\n",
    "# Filtrando o DataFrame para remover linhas onde 'sentiment' é uma string vazia\n",
    "data = data[data['sentiment'] != '']\n",
    "\n",
    "# Ou, se você quiser remover linhas onde 'sentiment' é nulo\n",
    "data = data[data['sentiment'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d5aad6",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3b513b7-6aa1-4592-a037-2ee61255af1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BertForSequenceClassification' from 'transformers' (C:\\Users\\arthu\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, BertForSequenceClassification\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertForSequenceClassification\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'BertForSequenceClassification' from 'transformers' (C:\\Users\\arthu\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "# Preparar os dados de entrada e saída\n",
    "X = data['content'].astype(str).tolist() \n",
    "y = data['sentiment'].tolist()\n",
    "\n",
    "# Codificar os rótulos\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Dividir os dados em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Carregar o tokenizador e o modelo do bertimbau\n",
    "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
    "model = BertForSequenceClassification.from_pretrained('neuralmind/bert-base-portuguese-cased', num_labels=len(label_encoder.classes_))\n",
    "\n",
    "# Tokenizar os textos\n",
    "def tokenize_function(texts):\n",
    "    return tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=128)\n",
    "\n",
    "train_encodings = tokenize_function(X_train)\n",
    "test_encodings = tokenize_function(X_test)\n",
    "\n",
    "# Criar os DataLoaders para treinamento e teste\n",
    "class ReviewsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = ReviewsDataset(train_encodings, y_train)\n",
    "test_dataset = ReviewsDataset(test_encodings, y_test)\n",
    "\n",
    "# Configurar os parâmetros de treinamento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "# Treinar o modelo\n",
    "trainer.train()\n",
    "\n",
    "# Avaliar o modelo\n",
    "results = trainer.evaluate()\n",
    "print(results)\n",
    "\n",
    "model.save_pretrained('./bertimbau_emocao')\n",
    "tokenizer.save_pretrained('./bertimbau_emocao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da66dedc-a8ee-4ca6-9aca-5b76e24af3c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./modelo_bertimbau_emocao\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./modelo_bertimbau_emocao\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save_pretrained('./modelo_bertimbau_emocao')\n",
    "tokenizer.save_pretrained('./modelo_bertimbau_emocao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972c400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o tokenizador e o modelo treinado\n",
    "tokenizer = BertTokenizer.from_pretrained('./modelo_bertimbau_emocao')\n",
    "model = BertForSequenceClassification.from_pretrained('./modelo_bertimbau_emocao')\n",
    "\n",
    "# Definir o dataset\n",
    "class ReviewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "val_dataset = ReviewsDataset(X_val, y_val, tokenizer)\n",
    "\n",
    "# Obter previsões\n",
    "def get_predictions(dataset):\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    for batch in torch.utils.data.DataLoader(dataset, batch_size=8):\n",
    "        input_ids = batch['input_ids'].to(model.device)\n",
    "        attention_mask = batch['attention_mask'].to(model.device)\n",
    "        labels = batch['labels'].to(model.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            predictions.extend(preds)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    return np.array(predictions), np.array(true_labels)\n",
    "\n",
    "# Função para prever a emoção de um texto\n",
    "def predict_emotion(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    pred = torch.argmax(probs, dim=1)\n",
    "    return label_encoder.inverse_transform(pred.cpu().numpy())[0]\n",
    "\n",
    "# Obter previsões e etiquetas verdadeiras\n",
    "y_pred, y_true = get_predictions(val_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299ffaf9-a64a-4990-a257-b2edf4fe4915",
   "metadata": {},
   "source": [
    "# Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4fbb276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  emotion\n",
      "0  Compro a bastante tempo, nunca tive problemas,...    anger\n",
      "1  As lojas são boas, tem bons vendedores. Mas a ...    anger\n",
      "2  Eu até que ainda compro no App,mas,depois que ...  sadness\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lista de avaliações e emoções retiradas do Google Play refêrentes oo app da shopee\n",
    "dataTeste ={\n",
    "    'review': ['Compro a bastante tempo, nunca tive problemas, o que mudou nestes últimos dois meses, a encomenda sai, mas não chega, a data de entrega é alterada automaticamente no aplicativo e a plataforma não resolve a citação, não faz o reembolso e nisso, estou a quase dois meses sem receber a encomenda e sem reembolso, a empresa não soluciona nada! E assim se repete com novas compras!',\n",
    "    'As lojas são boas, tem bons vendedores. Mas a Shopee é péssima. Tem um atendimento ao cliente péssimo, não sabem o que estão fazendo. Logística terrível e nunca entregam no prazo. E não sabem dar uma resposta coerente. Pode falar com 10 atendentes diferentes e todos vão falar uma versão diferente. O mínimo é uma estrela, mas se tivesse a opção zero, essa seria a minha com toda a certeza. Acho que as palavras incompetência e descaso resumem o serviço prestado.',\n",
    "    'Eu até que ainda compro no App,mas,depois que comprei um produto,onde o vendedor garantiu ser original,porém não era original e o produto estragou em 1 mês e eu não pude pedir a devolução ou reembolso,fiquei muito desanimado com a Shopee. E,além de tudo, fizeram um programa fidelidade que é a maior enganação, me rebaixaram de nível, mesmo tendo alcançado os pontos necessários pra subir de nível. Esse programa é somente pra recompensar a própria shoppe e nunca os usuários.'],\n",
    "    'emotion': ['anger','anger','sadness']\n",
    "    }\n",
    "\n",
    "df = pd.DataFrame(dataTeste)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5d19a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'compro bastante tempo nunca problemas mudou nestes últimos dois meses encomenda sai chega data entrega alterada automaticamente aplicativo plataforma resolve citação faz reembolso nisso quase dois meses receber encomenda reembolso empresa soluciona nada assim repete novas compras'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'] = df['review'].apply(lambda x: regex.sub(r'[^\\p{Latin}]', u' ', str(x)))\n",
    "df['review'] = df['review'].apply(lambda x: str(x).lower())\n",
    "df['review'] = df['review'].apply(remove_stopwords)\n",
    "\n",
    "df.loc[0,'review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a72775f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emoção prevista: \n",
      "0    anger\n",
      "1    anger\n",
      "2    anger\n",
      "Name: previsao, dtype: object\n",
      "\n",
      "Emoção real: \n",
      "0      anger\n",
      "1      anger\n",
      "2    sadness\n",
      "Name: emotion, dtype: object\n"
     ]
    }
   ],
   "source": [
    "emotion = df\n",
    "\n",
    "emotion['previsao'] = emotion['review'].apply(predict_sentiment)\n",
    "\n",
    "print('Emoção prevista: ')\n",
    "print(emotion['previsao'])\n",
    "print()\n",
    "print('Emoção real: ')\n",
    "print(emotion['emotion'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
